package com.pacbio.secondary.smrtlink.database

import java.util.UUID

import com.pacbio.secondary.smrtlink.dependency.Singleton
import com.pacbio.secondary.smrtlink.services.PacBioServiceErrors.{
  ResourceNotFoundError,
  UnprocessableEntityError
}
import com.pacbio.secondary.smrtlink.actors.CommonMessages.MessageResponse
import com.pacbio.secondary.smrtlink.actors._
import com.pacbio.secondary.smrtlink.analysis.jobs.AnalysisJobStates
import com.pacbio.secondary.smrtlink.analysis.jobs.JobModels.{
  EngineJob,
  JobEvent
}
import com.pacbio.secondary.smrtlink.models._
import com.pacificbiosciences.pacbiobasedatamodel.SupportedRunStates
import com.typesafe.scalalogging.LazyLogging

import scala.concurrent.ExecutionContext.Implicits._
import scala.concurrent.Future
import slick.jdbc.PostgresProfile.api._
import org.joda.time.{DateTime => JodaDateTime}

import scala.util.control.NonFatal
import scala.util.{Success, Try}

/**
  * RunDao that stores run designs in a Slick database.
  */
class DatabaseRunDao(db: Database, parser: DataModelParser)
    extends RunDao
    with DaoFutureUtils
    with LazyLogging {
  import TableModels._

  /**
    * These are event hooks to trigger the updating of Multi-Job state from changes in the Run State
    */
  private def updateMultiJobState(
      jobId: Int,
      updateState: AnalysisJobStates.JobStates,
      jobQuery: Query[EngineJobsT, EngineJobsT#TableElementType, Seq],
      msg: String): Future[EngineJob] = {

    def toJobEvent(engineJob: EngineJob): JobEvent = {
      val msg =
        s"RunDesign Updating multi-job id:${engineJob.id} type:${engineJob.jobTypeId} state to from ${engineJob.state} to $updateState"

      JobEvent(
        UUID.randomUUID(),
        engineJob.id,
        updateState,
        msg,
        JodaDateTime.now()
      )
    }

    val q = for {
      job <- jobQuery.result.head
      _ <- DBIO.seq(engineJobs
                      .filter(_.id === job.id)
                      .map(j => (j.state, j.updatedAt))
                      .update(updateState, JodaDateTime.now()),
                    jobEvents += toJobEvent(job))
      updatedJob <- engineJobs.filter(_.id === jobId).result.headOption
    } yield updatedJob

    db.run(q.transactionally).flatMap(failIfNone(msg))
  }

  private def submitMultiJob(jobId: Int): Future[EngineJob] = {
    val q0 = qGetEngineJobByState(AnalysisJobStates.CREATED)
      .filter(_.isMultiJob === true)
      .filter(_.id === jobId)

    val msg =
      s"Failed to find Job $jobId in state ${AnalysisJobStates.CREATED}"
    val sx = AnalysisJobStates.SUBMITTED

    updateMultiJobState(jobId, sx, q0, msg)
  }

  private def terminateMultiJob(jobId: Int): Future[EngineJob] = {
    // This isn't completely clear how this interacts with the ICS Run states. This really, really needs to be a FSM.
    // If the job is in the CREATED
    val states: Set[AnalysisJobStates.JobStates] =
      Set(AnalysisJobStates.RUNNING, AnalysisJobStates.CREATED)

    val q0 = qGetEngineJobsByStates(states)
      .filter(_.isMultiJob === true)
      .filter(_.id === jobId)

    val msg = s"Failed to find Job $jobId in states $states"
    val sx = AnalysisJobStates.TERMINATED

    // This should attempt to propagate the errorMessage of the Job
    updateMultiJobState(jobId, sx, q0, msg)
  }

  private def runMultiJobUpdate(summary: RunSummary): Future[String] = {

    val sx: (SupportedRunStates, Option[Int]) =
      (summary.status, summary.multiJobId)
    def toMessage(job: EngineJob) =
      s"Run ${summary.uniqueId} Updated MultiJob id:${job.id} state to ${job.state}"

    def toMessageAndLog(job: EngineJob): Future[String] = Future {
      val msg = toMessage(job)
      logger.info(msg)
      msg
    }

    sx match {
      case (SupportedRunStates.COMPLETE, Some(multiJobId)) =>
        // In principle, this could be done from the Running state and the analysis jobs would start as
        // soon as each subreadset has been generated by Primary and imported into SL.
        // However, for simplicity and to avoid terminating running analysis jobs created that have been
        // created while the Run has been executing, we'll wait till the run is entire completed and imported in SL.
        submitMultiJob(multiJobId).flatMap(toMessageAndLog)
      case (SupportedRunStates.ABORTED, Some(multiJobId)) =>
        terminateMultiJob(multiJobId).flatMap(toMessageAndLog)
      case (SupportedRunStates.TERMINATED, Some(multiJobId)) =>
        terminateMultiJob(multiJobId).flatMap(toMessageAndLog)
      case (state: SupportedRunStates, Some(multiJobId)) =>
        Future.successful(
          s"No updatable action for MultiJob id:$multiJobId from RunSummary state:$state")
      case (_, None) => Future.successful(s"Run ${summary.uniqueId}")
    }
  }

  private def updateOrCreate(
      uniqueId: UUID,
      update: Boolean,
      parseResults: Option[ParseResults] = None,
      setReserved: Option[Boolean] = None): Future[RunSummary] = {

    require(update || parseResults.isDefined,
            "Cannot create a run without ParseResults")

    val action =
      runSummaries.filter(_.uniqueId === uniqueId).result.headOption.flatMap {
        prev =>
          if (prev.isEmpty && update)
            throw new ResourceNotFoundError(
              s"Unable to find resource $uniqueId")
          if (prev.isDefined && !update)
            throw new UnprocessableEntityError(
              s"Resource $uniqueId already exists")

          val wasReserved = prev.map(_.reserved)
          val reserved = setReserved.orElse(wasReserved).getOrElse(false)
          val summary = parseResults
            .map(_.run.summarize)
            .orElse(prev)
            .get
            .copy(reserved = reserved)

          val summaryUpdate =
            Seq(runSummaries.insertOrUpdate(summary).map(_ => summary))

          val dataModelAndCollectionsUpdate = parseResults
            .map { res: ParseResults =>
              if (res.run.uniqueId != uniqueId)
                throw new UnprocessableEntityError(
                  s"Cannot update run $uniqueId with data model for run ${res.run.uniqueId}")

              val collectionsUpdate =
                res.collections.map(c => collectionMetadata.insertOrUpdate(c))
              val dataModelUpdate = dataModels.insertOrUpdate(
                DataModelAndUniqueId(res.run.dataModel, uniqueId))
              collectionsUpdate :+ dataModelUpdate
            }
            .getOrElse(Nil)

          DBIO
            .sequence(summaryUpdate ++ dataModelAndCollectionsUpdate)
            .map(_ => summary)
      }

    db.run(action.transactionally) andThen {
      case trySummary: Try[RunSummary] =>
        trySummary
          .map(runMultiJobUpdate)
          .recoverWith {
            case ex: ResourceNotFoundError =>
              // The job with an id or specific state was not found. This might yield false negatives
              Success("")
            case NonFatal(ex) =>
              logger.error(s"Failed to update MultiJob ${ex.getMessage}")
              Success("")
          }
    }
  }

  override def getRuns(criteria: SearchCriteria): Future[Set[RunSummary]] = {
    var query: Query[RunSummariesT, RunSummariesT#TableElementType, Seq] =
      runSummaries

    if (criteria.name.isDefined)
      query = query.filter(_.name === criteria.name.get)

    if (criteria.substring.isDefined)
      query = query.filter { r =>
        (r.name.indexOf(criteria.substring.get) >= 0)
          .||(r.summary.getOrElse("").indexOf(criteria.substring.get) >= 0)
      }

    if (criteria.createdBy.isDefined)
      query = query
        .filter(_.createdBy.isDefined)
        .filter(_.createdBy === criteria.createdBy)

    if (criteria.reserved.isDefined)
      query = query.filter(_.reserved === criteria.reserved.get)

    db.run(query.result).map(_.toSet)
  }

  override def getRun(id: UUID): Future[Run] = {
    val summary = runSummaries.filter(_.uniqueId === id)
    val model = dataModels.filter(_.uniqueId === id)
    val run = summary.join(model).result.headOption.map { opt =>
      opt
        .map { res =>
          res._1.withDataModel(res._2.dataModel)
        }
        .getOrElse {
          throw new ResourceNotFoundError(s"Unable to find resource $id")
        }
    }

    db.run(run)
  }

  override def createRun(create: RunCreate): Future[RunSummary] =
    Future(parser(create.dataModel)).flatMap { r =>
      updateOrCreate(r.run.uniqueId, update = false, Some(r), None)
    }

  override def updateRun(id: UUID, update: RunUpdate): Future[RunSummary] =
    Future(update.dataModel.map(parser.apply)).flatMap { r =>
      updateOrCreate(id, update = true, r, update.reserved)
    }

  override def deleteRun(id: UUID): Future[MessageResponse] = {
    val action = DBIO
      .seq(
        collectionMetadata.filter(_.runId === id).delete,
        dataModels.filter(_.uniqueId === id).delete,
        runSummaries.filter(_.uniqueId === id).delete
      )
      .map(_ => MessageResponse(s"Successfully deleted run design $id"))
    db.run(action.transactionally)
  }

  override def getCollectionMetadatas(
      runId: UUID): Future[Seq[CollectionMetadata]] =
    db.run(collectionMetadata.filter(_.runId === runId).result)

  override def getCollectionMetadata(
      runId: UUID,
      uniqueId: UUID): Future[CollectionMetadata] = {
    db.run {
        collectionMetadata
          .filter(_.runId === runId)
          .filter(_.uniqueId === uniqueId)
          .result
          .headOption
      }
      .map(_.getOrElse(throw new ResourceNotFoundError(
        s"No collection with id $uniqueId found in run $runId")))

  }
}

/**
  * Provides a DatabaseRunDao.
  */
trait DatabaseRunDaoProvider extends RunDaoProvider {
  this: DalProvider with DataModelParserProvider =>

  override val runDao: Singleton[RunDao] =
    Singleton(() => new DatabaseRunDao(db(), dataModelParser()))
}
