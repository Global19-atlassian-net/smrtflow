#!/usr/bin/env python
import argparse
import logging
from logging.handlers import RotatingFileHandler
import os
import subprocess
import sys
import json
import tempfile
import datetime
from collections import namedtuple

__version__ = "0.3.1"
__author__ = "mkocher"

log = logging.getLogger(__name__)

_BIN_DIR = os.path.abspath(os.path.dirname(__file__))
_BUNDLE_ROOT = os.path.dirname(_BIN_DIR)

# Default config file locations. Overridable from commandline
_SL_CONFIG = os.path.join(_BUNDLE_ROOT, "smrtlink-system-config.json")
# Migration State file
_MIGRATION_JSON = os.path.join(_BUNDLE_ROOT, "legacy-migration.json")
# Jvm options for all scala tools that are invoked as a subprocess. This was increased for the bundler-migrate-legacy-db
_JAVA_OPTS = "-Xmx8096m -Xms8096m -Djava.library.path="
_LOG_FORMAT = '[%(levelname)s] %(asctime)-15s %(message)s'
_LOG_STDOUT_FORMAT = "%(message)ss"
# Default Log file name that will be used if an explicit log file is not provided
_DEFAULT_LOG_FILE_NAME = "dbctrl.log"
# This will only be used when postgres is started up
_DEFAULT_POSTGRES_LOG_FILE_NAME = "postgres.log"
# Name of database to create for wso2
_WSO2_DB_NAME = "wso2am"

REQUIRED_EXES = ('initdb',
                 'pg_ctl',
                 'createdb',
                 'psql',
                 'createuser',
                 'smrt-db-tool')


class DbConfig(namedtuple("DbConfig", ["db_name", "pg_data_dir", "pg_backup_dir", "host", "port", "user", "password", "log_file"])):
    def to_fd(self):
        # used in .format(**_d)
        return dict(t=self.port, h=self.host, g=self.pg_data_dir, b=self.pg_backup_dir, n=self.db_name, u=self.user, p=self.password)

    def to_env(self):
        env = os.environ.copy()
        env['PGPASSWORD'] = self.password
        return env


class MigrationStatus(object):
    # (mkocher)(2017-7-26) Keeping this here for now. This might be necessary for the interface with installer.
    def __init__(self, was_successful, updated_at, comment):
        # should this have more than one state?
        self.was_successful = was_successful
        self.updated_at = updated_at
        self.comment = comment

    def __repr__(self):
        _d = dict(s=self.was_successful, u=self.updated_at,
                  k=self.__class__.__name__)
        return "<{k} successful:{s} updated at:{u} >".format(**_d)

    def to_dict(self):

        _d = dict(was_successful=self.was_successful,
                  updated_at=str(self.updated_at),
                  comment=self.comment)
        return _d

    @staticmethod
    def from_d(d):
        return MigrationStatus(d['was_successful'], d['updated_at'], d['comment'])

    def write(self, output_file):
        d = self.to_dict()
        with open(output_file, 'w+') as f:
            f.write(json.dumps(d, indent=4, sort_keys=True))
        return d


class MigrationConfig(object):
    # (mkocher)(2017-7-26) Keeping this here for now. This is no longer directly used in here, but keeping
    def __init__(self, wso2_root_path):
        self.wso2_root_dir = wso2_root_path

    def __repr__(self):
        _d = dict(k=self.__class__.__name__,
                  w=self.wso2_root_dir)
        return "<{k} wso2 root:{w} >".format(**_d)

    @staticmethod
    def from_d(d):
        wso2_root_path = d['PREVIOUS_INSTALL_DIR']
        return MigrationConfig(wso2_root_path)


def subparser_builder(subparser, subparser_id, description, options_func, exe_func):
    p = subparser.add_parser(subparser_id, help=description,
                             formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    options_func(p)
    p.set_defaults(func=exe_func)
    return p


def get_parser():
    desc = "Tool to interact with Postgres 9.6.x. Required exes in PATH {}".format(REQUIRED_EXES)
    p = argparse.ArgumentParser(version=__version__,
                                description=desc,
                                formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    def base_opts(p_):
        f = p_.add_argument
        f('-c', "--config", help="Path to smrtlink-system-config.json", default=_SL_CONFIG)
        f('--log-file', help="Log file. The default value will be pulled from the {}".format(_SL_CONFIG))
        f('--log-level', default=logging.INFO, help="Log level when emitting to a log file")
        f('--stdout-level', default=logging.WARN, help="Log level when emitting to stdout")
        f('--quiet', default=False, action="store_true", help="Enable ERROR level logging to stdout and log")
        f('--debug', default=False, action="store_true", help="Enable DEBUG level logging to stdout and log")
        return p_

    sp = p.add_subparsers(help='commands')

    def builder(subparser_id, description, options_func, exe_func):
        subparser_builder(sp, subparser_id, description, options_func, exe_func)

    def create_opts(px):
        px.add_argument('--wso2-dir', required=False,
                        help="Path to WSO2 directory containing a dbscripts directory with sql files")
        px.add_argument('--wso2-init', required=False,
                        help="Path to sql file with wso2 initialization data")
        base_opts(px)
        return px

    def load_and_func(f):
        def wrapper(args):
            return f(load_db_config(args.config))
        return wrapper

    args_db_status = load_and_func(db_status)
    args_db_start = load_and_func(db_start)
    args_db_stop = load_and_func(db_stop)
    args_db_init = load_and_func(db_init)
    args_db_verify = load_and_func(db_verify)

    def args_db_create(args):
        dbc = load_db_config(args.config)
        return db_create(dbc, dbc.db_name)

    def args_db_setup(args):
        dbc = load_db_config(args.config)
        return db_setup(dbc, args.wso2_dir, args.wso2_init)

    desc_status = "Get status of the database. Will return non-zero exit code if db is not accessible"
    desc_start = "Start database server. Will skip startup if already running"
    desc_stop = "Stop Database server if db is running. "
    desc_init = "Initialize SL Postgres database server (will start up db and shutdown after initialization)"
    desc_create = "Create SL Postgres database (init must be called first)"
    desc_verify = "Verify Postgres is running, Postgres tables have been created and" \
                  "migrations have successfully be applied."
    desc_setup = "Setup Postgres db,tables,user and apply Postgres schema Migration. " \
                 "Can be called multiple times, or from a fresh install"

    builder("status", desc_status, base_opts, args_db_status)
    builder("start", desc_start, base_opts, args_db_start)
    builder("stop", desc_stop, base_opts, args_db_stop)
    builder("init", desc_init, base_opts, args_db_init)
    builder("create", desc_create, create_opts, args_db_create)
    builder("verify", desc_verify, base_opts, args_db_verify)
    builder("setup", desc_setup, create_opts, args_db_setup)

    return p

def _get_log_dir_from_d(d):
    p = d['pacBioSystem']['logDir'].encode("utf8", "ignore")
    return os.path.abspath(p)


def load_psql_log_path_from_d(d):
    return os.path.join(_get_log_dir_from_d(d), _DEFAULT_POSTGRES_LOG_FILE_NAME)


def load_db_config(path):
    """Load the DB config from the smrtlink-system-config.json"""

    d = json.load(open(path, 'r'))

    def to_a(sx):
        return sx.encode("utf8", "ignore")

    db_name = to_a(d['smrtflow']['db']['properties']['databaseName'])

    # Note these root prefixes are stored within the scala code as well
    pg_data_dir = os.path.join(os.path.abspath(to_a(d['pacBioSystem']['pgDataDir'])), "dbstore")

    pg_backup_dir = os.path.join(os.path.abspath(to_a(d['pacBioSystem']['pgDataDir'])), "backups")

    port = int(d['smrtflow']['db']['properties']['portNumber'])
    host = to_a(d['smrtflow']['db']['properties']['serverName'])

    password = to_a(d['smrtflow']['db']['properties']['password'])
    user = to_a(d['smrtflow']['db']['properties']['user'])

    psql_log_file = load_psql_log_path_from_d(d)

    return DbConfig(db_name, pg_data_dir, pg_backup_dir, host, port, user, password, psql_log_file)


def load_log_dir(path):
    """Load the System Level Logging dir from the System config."""
    d = json.load(open(path, 'r'))
    return _get_log_dir_from_d(d)


def _run_cmd(cmd, env=None):
    """Run cmd with no logging and return exit code"""
    px = subprocess.Popen(cmd, shell=True, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    px.wait()
    return px.returncode


def _run_cmd_and_log(cmd, env=None):
    """
    Run a cmd string and log the error (if an error occurs)

    :param cmd: Command string to run
    :param env: dict or None override ENV to run cmd in
    :return: exit code
    """

    env_str = "ENV {}".format(env) if env else ""
    log.debug("Running cmd '{}' {}".format(cmd, env_str))
    px = subprocess.Popen(cmd, shell=True, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    stdout, stderr = px.communicate()

    exit_code = px.returncode
    if exit_code != 0:
        log.error("Command {} failed with exit code {}".format(cmd, exit_code))
        log.error(stderr)
    else:
        log.debug("Successfully ran command {}".format(cmd))
        log.debug("Output {}".format(stdout))

    return exit_code


def _run_raise_on_failure(cmd, env=None, runner_func=_run_cmd_and_log):
    rcode = runner_func(cmd, env=env)
    if rcode != 0:
        raise RuntimeError("FAILED Command {}".format(cmd))
    return rcode


def check_if_running(db_config, fail_early=True, runner_func=_run_cmd):
    """
    Test to see if the db is up and running.

    :type db_config: DbConfig
    :type fail_early: Boolean
    :rtype: Boolean
    """
    rcode = db_status(db_config, fail_early=fail_early, runner_func=runner_func)
    return True if rcode == 0 else False


def check_if_running_or_raise(dbc):
    if check_if_running(dbc, runner_func=_run_cmd_and_log):
        return True
    else:
        raise RuntimeError("DB is not running {}".format(dbc))


def _fail_status_early(dbc):
    """Fail early if the PGDATA dir doesn't exist
    :type dbc: DbConfig
    """
    if not os.path.exists(dbc.pg_data_dir):
        raise IOError("Postgres is not running. Unable to find PGDATA dir {}".format(dbc.pg_data_dir))
    return dbc


def _start_db_or_raise(dbc):
    """Start or raise if can't start the db"""
    was_started = check_if_running(dbc)
    if not was_started:
        start_success = db_start(dbc)
        if start_success != 0:
            raise RuntimeError("Unable to start db successfully with config {}".format(dbc))

    return was_started


def _to_cmd(dbc, action, log_file=None):
    """
    The log file is only really configurable for start action
    :type dbc: DbConfig
    """
    _d = dbc.to_fd()
    _d['a'] = action
    if log_file is None:
        _d['x'] = ''
    else:
        _d['x'] = '-l {}'.format(log_file)
    cmd = "pg_ctl {a} {x} -w --pgdata {g} -o \"-p {t} -h {h}\"".format(**_d)
    return cmd


def _fix_postgres_config(path, var_run_dir='/tmp'):
    # workaround for config having references to /var/run/postgresq depending
    # on how it was installed
    # Note, there's a path length limitation of maximum 107 bytes
    if not os.path.exists(var_run_dir):
        os.mkdir(var_run_dir)
    # overwrite the `unix_socket_directories` value
    with open(path, 'a') as f:
        f.write("# Custom override\n")
        f.write("unix_socket_directories = '{}'\n".format(var_run_dir))
    return var_run_dir


def db_init(dbc):
    """Fresh/clean initialization of the database

    1. Create pg data dir (if necessary)
    2. call initdb (this will raise if the db already exists)

    :type dbc: DbConfig
    """
    def to_p(x):
        return os.path.join(dbc.pg_data_dir, x)

    # Create the PG dbstore dir if it doesn't exist.
    root_dir = dbc.pg_data_dir
    if not os.path.exists(root_dir):
        os.mkdir(root_dir)

    # create backup dir
    if not os.path.exists(dbc.pg_backup_dir):
        os.mkdir(dbc.pg_backup_dir)

    # simple way to see if an existing install is present
    if os.path.exists(os.path.join(dbc.pg_data_dir, 'postgresql.conf')):
        log.info("Detected exiting install. Skipping init in {}".format(dbc.pg_data_dir))
        return 0

    # write the password to tmp file
    t = tempfile.NamedTemporaryFile().name
    with open(t, 'w+') as f:
        f.write(dbc.password)

    _d = dict(g=dbc.pg_data_dir, u=dbc.user, t=t)
    cmd = "initdb --pgdata {g} --username {u} --pwfile={t} --encoding=UTF-8 --locale=en_US.UTF-8".format(**_d)

    rcode = _run_cmd_and_log(cmd)

    # see comments above. Perhaps this should be removed
    _fix_postgres_config(to_p("postgresql.conf"))

    if os.path.exists(t):
        os.remove(t)
    return rcode


def _get_dbs(dbc, db_name):
    """Get all databases that have the given db name and user"""
    cmd = "psql -lqtA --port={t} --no-password --host={h} -U {u}".format(**dbc.to_fd())
    p = subprocess.Popen(cmd, shell=True, env=dbc.to_env(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    p.wait()
    if p.returncode == 0:
        return [line.strip().split("|") for line in p.stdout.readlines() if line.startswith("{db_name}|{user}".format(db_name=db_name, user=dbc.user))]
    else:
        log.error("Failed to get db list")
        return []


def db_create(dbc, db_name):
    """Will create a postgres SL db


    :param db_name: Database name

    :type db_name: str
    :type dbc: DbConfig
    """

    was_started = check_if_running(dbc)
    _start_db_or_raise(dbc)

    db_names = _get_dbs(dbc, db_name)

    if not db_names:
        _d = dbc.to_fd()
        env = dbc.to_env()
        cmd = "createdb --no-password --echo --port={t} --host={h} --username={u} --encoding=UTF-8 --locale=en_US.UTF-8 {db_name}".format(db_name=db_name, **_d)
        rcode = _run_cmd_and_log(cmd, env=env)
    else:
        rcode = 0
        log.debug("Founds databases {}".format(db_names))

    # if the db was original running, keep it running, otherwise, shut it down
    if not was_started:
        db_stop(dbc)

    return rcode


def db_create_main(dbc):
    return db_create(dbc, dbc.db_name)


def db_start(dbc, fail_early=True):
    """:type dbc: DbConfig"""

    if fail_early:
        _fail_status_early(dbc)

    if not check_if_running(dbc):
        return _run_cmd_and_log(_to_cmd(dbc, "start", log_file=dbc.log_file))
    else:
        log.info("Database is already started. Skipping startup")
        return 0


def db_start_no_fail_early(dbc):
    return db_start(dbc, fail_early=False)


def db_stop(dbc):
    """:type dbc: DbConfig"""
    if check_if_running(dbc):
        return _run_cmd_and_log(_to_cmd(dbc, "stop"))
    else:
        log.info("Database is not running. No stopping action necessary")
        return 0


def db_status(dbc, fail_early=True, runner_func=_run_cmd_and_log):
    """Get the Status of the Database

    :param fail_early: Check of PGDATA path existence and fail if not found (or empty)
    :type dbc: DbConfig
    """
    if fail_early:
        _fail_status_early(dbc)

    cmd = "pg_ctl status --silent --pgdata {g} -o \"-p {t}\"".format(**dbc.to_fd())
    return runner_func(cmd)


def db_verify(dbc):
    """:type dbc: DbConfig"""
    check_if_running_or_raise(dbc)

    cmd = "smrt-db-tool migrate --log2stdout --user {u} --password {p} --server {h} --port {t} --db-name {n}".format(**dbc.to_fd())
    return _run_cmd_and_log(cmd)

def db_create_wso2(dbc, wso2_dir, wso2_init):
    wso2_script_files = [
        "{wso2_dir}/dbscripts/postgresql.sql".format(wso2_dir=wso2_dir),
        "{wso2_dir}/dbscripts/mb-store/postgresql-mb.sql".format(wso2_dir=wso2_dir),
        "{wso2_dir}/dbscripts/apimgt/postgresql.sql".format(wso2_dir=wso2_dir),
        wso2_init
    ]

    if wso2_dir is None:
        log.info("No WSO2 directory provided. Skipping creation for WSO2 database")
        return 0

    db_names = _get_dbs(dbc, _WSO2_DB_NAME)
    if not db_names:
        createdb_result = db_create(dbc, _WSO2_DB_NAME)

        if createdb_result == 0:
            env = dbc.to_env()
            for script in wso2_script_files:
                cmd = "psql -q --port={t} --no-password --host={h} -U {u} -f {script} {db_name}".format(script=script, db_name=_WSO2_DB_NAME, **dbc.to_fd())
                script_result = _run_cmd_and_log(cmd, env=env)
                if script_result != 0:
                    return script_result
            return 0
        else:
            # the db creation failed, there's nothing more we can do here. The wso2 tables won't be created.
            return createdb_result
    return 0


def db_setup(dbc, wso2_dir=None, wso2_init=None):
    """ Creates the postgres database(s)

    1. create initial db (if necessary)
    2. create user (if necessary)

    Note, this doesn't handle the legacy migration

    :param wso2_dir: Optional Path to the WSO2 directory
    :type wso2_dir: None | str

    :param wso2_init: Optional Path to wso2 init script
    :type wso2_init: None | str

    :type dbc: DbConfig
    """
    def to_b(n):
        # to boolean func that returns True if the exit code == 0
        return True if n == 0 else False

    def _apply_funcs(funcs, init_state):
        if funcs and init_state:
            f = funcs.pop()
            exit_code = f(dbc)
            sx = to_b(exit_code)
            if sx:
                log.debug("db func {} was successful".format(f.__name__))
                return _apply_funcs(funcs, sx)
            else:
                log.error("db func {} FAILED with exit code {}".format(f.__name__, exit_code))
                return False
        else:
            return init_state

    def _wso2_create_wrapper(dbc_):
        return db_create_wso2(dbc_, wso2_dir, wso2_init)

    was_started = check_if_running(dbc, fail_early=False)

    # if the db is running, then db init, createdb was successful
    if was_started:
        db_funcs = [_wso2_create_wrapper, db_create_main, db_start_no_fail_early]
        was_successful = _apply_funcs(db_funcs, True)
    else:
        db_funcs = [_wso2_create_wrapper, db_create_main, db_start_no_fail_early, db_init]
        was_successful = _apply_funcs(db_funcs, True)

    if not was_started:
        log.debug("Initial state of db was not running. Calling shutdown")
        return db_stop(dbc)

    return 0 if was_successful else 1


def setup_logger(alog, level=logging.INFO, file_name=None,
                 log_filter=None,
                 str_formatter='[%(levelname)s] %(asctime)-15s [%(name)s %(funcName)s %(lineno)d] %(message)s'):
    """
    Because we want to log to the output dir defined in the smrtlink-system-config, the logging config
    needs to be delayed until after the config is parsed.

    :param alog: a log instance
    :param level: (int) Level of logging debug
    :param file_name: (str, None) if None, stdout is used, str write to file
    :param log_filter: (LogFilter, None)
    :param str_formatter: (str) log formatting str
    """
    alog.setLevel(logging.DEBUG)
    # this is the magic that enables the log to have different handlers with different log levels
    alog.propagate = 0

    if file_name is None:
        handler = logging.StreamHandler(sys.stdout)
    else:
        max_bytes = 1000 * 1000
        handler = RotatingFileHandler(file_name, backupCount=5, maxBytes=max_bytes)

    formatter = logging.Formatter(str_formatter)
    handler.setFormatter(formatter)
    handler.setLevel(level)

    if log_filter:
        handler.addFilter(log_filter)

    alog.addHandler(handler)

    return alog


def main(argv=None):
    args = sys.argv[1:] if argv is None else argv[1:]

    started_at = datetime.datetime.now()

    p = get_parser()

    pargs = p.parse_args(args)

    # the Logging setup is a bit involved to enable "logging" to stdout as well as
    # writing to a file.
    log_level_stdout = pargs.stdout_level
    log_level_file = pargs.log_level

    if pargs.quiet:
        log_level_stdout = logging.ERROR
        log_level_file = logging.ERROR

    if pargs.debug:
        log_level_stdout = logging.DEBUG
        log_level_file = logging.DEBUG

    if pargs.log_file is None:
        log_dir = load_log_dir(pargs.config)
        apply_config_log = os.path.join(os.path.abspath(log_dir), _DEFAULT_LOG_FILE_NAME)
    else:
        apply_config_log = os.path.abspath(os.path.expanduser(pargs.log_file))

    # Setup Logger to file
    setup_logger(log, log_level_file, file_name=apply_config_log, str_formatter=_LOG_FORMAT)

    # Setup logger to stdout. This is not quite right. Errors won't get written to stderr
    setup_logger(log, log_level_stdout, file_name=None, str_formatter=_LOG_STDOUT_FORMAT)

    log.debug("Parsed args: {}".format(pargs))

    try:
        exit_code = pargs.func(pargs)
    except Exception as e:
        log.exception(e)
        exit_code = 1

    run_time = (datetime.datetime.now() - started_at).total_seconds()
    log.info("Exiting {f} {v} with exit code {e} in {r:.2f} sec.".format(e=exit_code, r=run_time, f=os.path.basename(__file__), v=__version__))
    return exit_code


if __name__ == '__main__':
    sys.exit(main(argv=sys.argv))
